{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Ensemble</font> ASCII\n",
    "---\n",
    "Nous continuerons avec l'exemple du code ASCII utilisé dans le tutoriel perceptron pour implémenter un réseau de neurones à feed forward, mais pour séparer les différentes classes de caractères ASCII, c'est-à-dire un classifieur multiclasse.\n",
    "\n",
    "Les caractères de notre ensemble de données peuvent appartenir à 5 classes différentes, à savoir : \n",
    "\n",
    "* Caractères de contrôle : codés de 0-31 et le 127\n",
    "* Caractères spéciaux (signes de ponctuation et opérateurs mathématiques) : codés de 32-47, 58-64, 91-96, 123-126\n",
    "* Chiffres : codés de 48-57\n",
    "* Majuscules : codés de 65-90\n",
    "* Minuscules : codé de 97-122\n",
    "\n",
    "\n",
    "![ascii-code](images/ascii_code.png)\n",
    "\n"
   ]
  },
  {
   "source": [
    "---\n",
    "## <font color=\"red\">1 | CRÉATION DE L'</font>ENSEMBLE\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "La première chose que nous allons faire est d'importer les bibliothèques nécessaires :\n",
    "\n",
    "* [numpy](https://numpy.org/) : Extension destinée à manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions mathématiques opérant sur ces tableaux.\n",
    "* [pickle](https://docs.python.org/3/library/pickle.html) : Ce module permet de sauvegarder dans un fichier, au format binaire,  n'importe quel objet Python.\n",
    "* [tabulate](https://pypi.org/project/tabulate/) : Pour afficher des tableaux d'une manière facile à lire. \n",
    "* [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) : Bibliothèque libre Python destinée à l'apprentissage automatique.\n",
    "\n",
    "Nous allons utiliser la classe `LabelBinarizer` de `sklearn` pour transformer les étiquettes (strings) en étiquettes binaires.\n",
    "\n",
    "Nous définissons également une constante `RANDOM_SEED` qui sera utilisée dans différentes fonctions pour garantir que les données générées  sont reproductibles.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "source": [
    "Nous convertissons ensuite le tableau de codes ASCII dans l'image ci-dessus en code, ce sera notre ensemble de données. Comme vous pouvez le voir, nous définissons les primitives (bits) et l'étiquette de classe à laquelle correspond chaque ensemble de bits.\n",
    "\n",
    "À la fin de la cellule, nous battons l'ensemble de données en utilisant `RANDOM_SEED` comme *seed* pour la fonction aléatoire."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ascii_dataset = np.array([\n",
    "    [np.array([0, 0, 0, 0, 0, 0, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 0, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 0, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 0, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 1, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 1, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 1, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 0, 1, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 0, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 0, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 0, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 0, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 1, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 1, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 1, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 0, 1, 1, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 0, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 0, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 0, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 0, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 1, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 1, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 1, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 0, 1, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 0, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 0, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 0, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 0, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 1, 0, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 1, 0, 1]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 1, 1, 0]), 'Control'],\n",
    "    [np.array([0, 0, 0, 1, 1, 1, 1, 1]), 'Control'],\n",
    "    [np.array([0, 0, 1, 0, 0, 0, 0, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 0, 0, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 0, 1, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 0, 1, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 1, 0, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 1, 0, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 1, 1, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 0, 1, 1, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 0, 0, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 0, 0, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 0, 1, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 0, 1, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 1, 0, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 1, 0, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 1, 1, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 0, 1, 1, 1, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 1, 0, 0, 0, 0]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 0, 0, 1]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 0, 1, 0]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 0, 1, 1]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 1, 0, 0]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 1, 0, 1]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 1, 1, 0]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 0, 1, 1, 1]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 1, 0, 0, 0]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 1, 0, 0, 1]), 'Digit'],\n",
    "    [np.array([0, 0, 1, 1, 1, 0, 1, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 1, 1, 0, 1, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 1, 1, 1, 0, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 1, 1, 1, 0, 1]), 'Special'],\n",
    "    [np.array([0, 0, 1, 1, 1, 1, 1, 0]), 'Special'],\n",
    "    [np.array([0, 0, 1, 1, 1, 1, 1, 1]), 'Special'],\n",
    "    [np.array([0, 1, 0, 0, 0, 0, 0, 0]), 'Special'],\n",
    "    [np.array([0, 1, 0, 0, 0, 0, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 0, 0, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 0, 0, 1, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 0, 1, 0, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 0, 1, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 0, 1, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 0, 1, 1, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 0, 0, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 0, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 0, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 0, 1, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 1, 0, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 1, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 1, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 0, 1, 1, 1, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 0, 0, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 0, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 0, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 0, 1, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 1, 0, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 1, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 1, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 0, 1, 1, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 1, 0, 0, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 1, 0, 0, 1]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 1, 0, 1, 0]), 'Upper'],\n",
    "    [np.array([0, 1, 0, 1, 1, 0, 1, 1]), 'Special'],\n",
    "    [np.array([0, 1, 0, 1, 1, 1, 0, 0]), 'Special'],\n",
    "    [np.array([0, 1, 0, 1, 1, 1, 0, 1]), 'Special'],\n",
    "    [np.array([0, 1, 0, 1, 1, 1, 1, 0]), 'Special'],\n",
    "    [np.array([0, 1, 0, 1, 1, 1, 1, 1]), 'Special'],\n",
    "    [np.array([0, 1, 1, 0, 0, 0, 0, 0]), 'Special'],\n",
    "    [np.array([0, 1, 1, 0, 0, 0, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 0, 0, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 0, 0, 1, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 0, 1, 0, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 0, 1, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 0, 1, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 0, 1, 1, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 0, 0, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 0, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 0, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 0, 1, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 1, 0, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 1, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 1, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 0, 1, 1, 1, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 0, 0, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 0, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 0, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 0, 1, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 1, 0, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 1, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 1, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 0, 1, 1, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 1, 0, 0, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 1, 0, 0, 1]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 1, 0, 1, 0]), 'Lower'],\n",
    "    [np.array([0, 1, 1, 1, 1, 0, 1, 1]), 'Special'],\n",
    "    [np.array([0, 1, 1, 1, 1, 1, 0, 0]), 'Special'],\n",
    "    [np.array([0, 1, 1, 1, 1, 1, 0, 1]), 'Special'],\n",
    "    [np.array([0, 1, 1, 1, 1, 1, 1, 0]), 'Special'],\n",
    "    [np.array([0, 1, 1, 1, 1, 1, 1, 1]), 'Control']\n",
    "])\n",
    "\n",
    "np.random.seed(seed=RANDOM_SEED)\n",
    "np.random.shuffle(ascii_dataset)\n",
    "\n",
    "ascii_dataset"
   ]
  },
  {
   "source": [
    "Maintenant, nous allons stocker toutes les primitives dans une variable appelée `features`, que nous utiliserons plus tard."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([features for features in ascii_dataset[:,0]])\n",
    "features"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### <font color=\"red\">1.1 - Encodage des</font> étiquettes\n",
    "---\n",
    "\n",
    "Dans les modèles ML, nous devons souvent convertir les données catégorielles, c'est-à-dire les données textuelles, en une représentation numérique que nos modèles prédictifs peuvent mieux comprendre.\n",
    "\n",
    "Dans notre ensemble de données, l'étiquette de chaque exemple est entièrement composé de texte. Comme vous le savez peut-être maintenant, nous ne pouvons pas avoir de texte dans nos données si nous allons exécuter un modèle quelconque. Donc, avant de pouvoir exécuter un modèle, nous devons préparer les données.\n",
    "\n",
    "La classe `LabelBinarizer` prend chaque nom de classe (étiquette) et elle les convertit en une nouvelle colonne et attribue une valeur 1 ou 0 (notation pour vrai / faux) à la colonne. Pour les étiquettes de notre ensemble de données, nous avons 5 valeurs possibles (Control, Special, Digit, Lower, Upper) et donc 5 variables binaires sont nécessaires. Une valeur 1 est placée dans la variable binaire pour le nom de la classe et des valeurs 0 pour les autres classes, par exemple :\n",
    "\n",
    "| Control&nbsp; | Special&nbsp; | Digit&nbsp; | Lower&nbsp; | Upper&nbsp; |\n",
    "|:---------:|:---------:|:-------:|:-------:|:-------:|\n",
    "| 1       | 0       | 0     | 0     | 0     |\n",
    "| 0       | 1       | 0     | 0     | 0     |\n",
    "| 0       | 0       | 1     | 0     | 0     |\n",
    "| 0       | 0       | 0     | 1     | 0     |\n",
    "| 0       | 0       | 0     | 0     | 1     |\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating an object of LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "\n",
    "# Extract the labels from the dataset\n",
    "labels = ascii_dataset[:,1]\n",
    "\n",
    "# Transrform the string labels into binary labels\n",
    "y = label_binarizer.fit_transform(labels)\n",
    "\n",
    "# Creating a list containing one dictionary for each example with the string label and the binary label\n",
    "outputs = np.array([{string_label:binary_label} for string_label, binary_label in zip(labels, y)])\n",
    "\n",
    "outputs"
   ]
  },
  {
   "source": [
    "La classe `LabelBinarizer` dispose d'une méthode de transformation inverse pour transformer un tableau d'étiquettes binaires en sa valeur de texte originale, transformons à nouveau les étiquettes binaires (y) en textuelles :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform back binary labels to string labels\n",
    "label_binarizer.inverse_transform(y)"
   ]
  },
  {
   "source": [
    "Il est évident que nous pouvons également obtenir l'étiquette texte à partir d'une seule étiequette binaire, comme indiqué ci-dessous"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform back only one binary label to string label\n",
    "label_binarizer.inverse_transform(np.array([y[0]]))"
   ]
  },
  {
   "source": [
    "Nous allons maintenant utiliser cette capacité d'inverser la transformation afin de créer un mapping entre les étiquettes de texte et sa valeur binaire correspondante, que nous utiliserons plus tard lorsque nous mettrons en œuvre notre modèle :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = {tuple(binary_label) : label_binarizer.inverse_transform(np.array([binary_label]))[0] for binary_label in np.unique(y, axis=0)}\n",
    "classes"
   ]
  },
  {
   "source": [
    "À ce stade, nous pouvons afficher les primitives (bit des caractères ASCII) et le l'étiquette texte et binaire associés à chacune d'entre elles."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tabulate(zip(features, labels, y), headers=[\"Features\", \"String label\", \"Binary label\"]))"
   ]
  },
  {
   "source": [
    "---\n",
    "## <font color=\"red\">2 | REPRÉSENTATION GRAPHIQUE DE</font> L'ENSEMBLE DE DONNÉES\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Le problème de nos jours est que la plupart des ensembles de données comportent un grand nombre de variables. En d'autres termes, ils ont un nombre élevé de dimensions le long desquelles les données sont distribuées. Dans notre ensemble de données, chaque exemple est composé de 8 bits (8 variables/dimensions).\n",
    "\n",
    "L'exploration visuelle des données peut alors devenir difficile et la plupart du temps même pratiquement impossible à faire manuellement. Cependant, une telle exploration visuelle est extrêmement importante dans tout problème lié aux données. Par conséquent, il est essentiel de comprendre comment visualiser des ensembles de données de grande dimension. Ceci peut être réalisé en utilisant des techniques connues sous le nom de réduction de dimensionnalité. À continuation on va utiliser la technique t-SNE qui est capable de capturer une grande partie de la structure locale des données de haute dimension, tout en la visualisant également en 2D.\n",
    "\n",
    "Nous utiliserons l'implémentation Scikit-Learn de l'algorithme dans ce tuto, donc il faut d'abord importer les librairies.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "Tout d'abord, on va créer 2 sous-ensmebles ; l'un pour l'entraînement et l'autre pour le test. C'est pourquoi nous allons programmer une fonction qui effectue un sous-échantillonnage stratifié pour un ensemble de données donné. Le terme **stratifié** signifie que l'échantillon préserve le même pourcentage de chaque classe (étiquette) que les données d'origine.\n",
    "\n",
    "Le code suivant prend l'ensemble des données, les étiquettes de l'ensemble, la taille de l'échantillon souhaité et une *seed*  qui garantit que l'échantillon généré est reproductible sur plusieurs appels de fonction. Nous utilisons la classe `StratifiedShuffleSplit` de scikit-learn. À la fin, on obtient le sous-échantillon pour `features` et `outputs`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "sss.get_n_splits(features, y)\n",
    "\n",
    "for train_index, test_index in sss.split(features, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    outputs_train, outputs_test = outputs[train_index], outputs[test_index]"
   ]
  },
  {
   "source": [
    "La classe de sklearn TSNE() est accompagnée d'une liste d'hyper paramètres qui peuvent être réglés pendant l'application de cette technique. Nous allons décrire les 2 premiers d'entre eux. Cependant, il est recommandé de les explorer tous si vous souhaitez en savoir plus :\n",
    " \n",
    "1. **n_components : int, optional (default: 2)** <br/>\n",
    "Il s'agit du paramètre de la dimension de l'espace inférieur vers lequel vous souhaitez convertir votre ensemble de données. Dans notre cas, la valeur doit être 2 car nous voulons visualiser l'ensemble dans un espace à 2 dimensions.\n",
    "\n",
    "2. **perplexity : float, optional (default: 30)** <br/>\n",
    "Il s'agit d'un paramètre pour le nombre de voisins les plus proches, sur la base duquel l't-SNE déterminera les voisins potentiels. En général, plus l'ensemble de données est grand, plus la valeur de perplexité doit être élevée.\n",
    "\n",
    "Ici, nous créons d'abord l'instance de t-SNE en Python et nous la stockons sous le nom de `features_tsne`. Ensuite, nous transformons avec `fit_transform` l'ensemble de données d'origine en sa forme bidimensionnelle, qui se présente sous la forme d'un tableau numpy. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tsne = TSNE(n_components=2, random_state=RANDOM_SEED).fit_transform(features)"
   ]
  },
  {
   "source": [
    "Enfin, nous créons un nuage de points où les étiquettes de couleur représentent chaque type de symbole ASCII. Dans le graphique, vous pouvez voir comment les 5 classes sont distribuées et il est évident qu'elles ne peuvent pas être séparées par une seule fonction linéaire."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coors = {key:value for (key, value) in zip(classes.values(), [[] for _ in range(5)])}\n",
    "y_coors = {key:value for (key, value) in zip(classes.values(), [[] for _ in range(5)])}\n",
    "\n",
    "for i in range(len(features_tsne)):        \n",
    "    x_coors[labels[i]].append(features_tsne[i][0])\n",
    "    y_coors[labels[i]].append(features_tsne[i][1])\n",
    "\n",
    "plt.figure(figsize=(14, 6))   \n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "marker = itertools.cycle(('x', 'p', 's', 'P', 'o')) \n",
    "handles =[plt.scatter(x_coors[class_], y_coors[class_], marker=next(marker)) for class_ in classes.values()]\n",
    "plt.legend(handles, classes.values(), scatterpoints=1, loc='lower left', ncol=3, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "---\n",
    "## <font color=\"red\">3 | STOCKER</font> L'ENSEMBLE DE DONNÉES\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Dans cette dernière partie, deux dictionnaires sont créés, le premier contiendra, sous les clés `TRAIN` et `TEST`, les primitives d'entrenaînement et de test, respectivement. Le seconde, utilisant les mêmes clés, stockera les étiquettes pour l'ensemble d'entrenaînement et de test, plus une clé supplémentaire `CLASSES` pour la correspondance entre les étiquettes binaires et textuelles.\n",
    "\n",
    "Nous utilisons `pickle` pour stocker les données dans des fichiers binaires afin de pouvoir les utiliser lors de l'implémentation d'un modèle quelconque."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = {'TRAIN': features_train, 'TEST': features_test}\n",
    "final_outpus = {'TRAIN': outputs_train, 'TEST': outputs_test, 'CLASSES': classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features['TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the files containing all the information about your dataset and saving them to the disk\n",
    "pickle_out = open(\"ascii_features.pickle\", \"wb\")\n",
    "pickle.dump(final_features, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"ascii_outputs.pickle\", \"wb\")\n",
    "pickle.dump(final_outpus, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}